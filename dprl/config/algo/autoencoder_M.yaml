name: autoencoder_M

total_steps: 100_000
batch_size: 16

base_channels: 128
base_shape: [3, 64, 64]
feedforward_dim: 2048

compile: False
n_devices: 4
n_nodes: 2

encoder:
  base_channels: ${algo.base_channels}
  in_shape: ${algo.base_shape}
  channels_mult: [1, 2, 4, 8]
  out_size: 1024
  mlp_feedforward_dim: ${algo.feedforward_dim}

decoder:
  base_channels: ${algo.base_channels}
  channels_mult: [8, 4, 2, 1]
  out_shape: ${algo.base_shape}
  mlp_feedforward_dim: ${algo.feedforward_dim}

discriminator:
  base_channels : 128
  base_shape : ${algo.base_shape}
  patch_size: [16, 16]
  stride: [8, 8]
  mlp_feedforward_dim: 1024
  mlp_depth: 2

action_model:
  in_dim: ${algo.encoder.out_size}
  action_dim: 7
  hidden_size: 1024
  depth: 4
  
categorical:
  stochastic_size: 32
  num_states: 32
  gradient_strategy: "st" # "st" | "gumbel"
  loss_strategy: "mse" # "gan" | "mse"
  generator:
    optim:
      _target_: torch.optim.AdamW
      lr: 8e-5
      eps: 1e-6
      weight_decay: 1e-8
  discriminator:
    optim:
      _target_: torch.optim.RMSprop
      lr: 8e-5
      eps: 1e-6
      weight_decay: 1e-8
