{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\Documents\\GaTech\\Fall2024\\diffusion-planning-rl\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import hydra\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf, SCMode\n",
    "import cv2\n",
    "\n",
    "from lightning import Fabric\n",
    "import glob\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dprl.data.utils import dotdict\n",
    "from dprl.algo.autoencoder import CategoricalAutoEncoder\n",
    "from dprl.algo.seq2seq import LatentDFModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    initialize(version_base=None, config_path=\"../dprl/config\")\n",
    "except ValueError:\n",
    "    hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "    initialize(version_base=None, config_path=\"../dprl/config\")\n",
    "\n",
    "cfg = compose(config_name=\"config\", overrides=[\"algo=diffusion_M_categorical\"])\n",
    "cfg = dotdict(OmegaConf.to_container(cfg, resolve=True, structured_config_mode=SCMode.DICT_CONFIG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"forced_diffusion_M\"\n",
    "\n",
    "fabric = Fabric(accelerator='gpu', precision=\"bf16-mixed\")\n",
    "\n",
    "def get_last_checkpoint(model_path : str):\n",
    "    checkpoints = glob.glob(f\"checkpoints/{model_path}/*.ckp\")\n",
    "    checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "    \n",
    "    model_params = torch.load(checkpoint, weights_only=True)['model']\n",
    "    \n",
    "    ae : CategoricalAutoEncoder = CategoricalAutoEncoder.from_config(fabric, cfg.algo, need_optim=False)\n",
    "    \n",
    "    model : LatentDFModel = LatentDFModel.from_config(fabric, cfg.algo, encoder=ae.encoder, decoder=ae.decoder, action_model=ae.action_model)\n",
    "    model.load_state_dict(model_params)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "model = get_last_checkpoint(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.abspath(\".\")\n",
    "data_root = os.path.join(root, \"datasets\", \"libero_10\")\n",
    "filename = \"KITCHEN_SCENE3_turn_on_the_stove_and_put_the_moka_pot_on_it_demo.hdf5\"\n",
    "data = h5py.File(os.path.join(data_root, filename), \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.diffusion.sampling_timesteps = 10\n",
    "\n",
    "# loop over tasks\n",
    "for file in os.listdir(data_root):\n",
    "    # print task name\n",
    "    print(f\"Eval Task: {file}\")\n",
    "    data = h5py.File(os.path.join(data_root, filename), \"r\")['data']\n",
    "\n",
    "    # loop over demos\n",
    "    # if this ends up being slow we can just use some percentage of the demos\n",
    "    total_mse = 0\n",
    "    # print(np.random.choice(list(data.keys()), 5))\n",
    "\n",
    "    for demo in tqdm(np.random.choice(list(data.keys()), 5)):\n",
    "        traj = data[demo]\n",
    "\n",
    "        # save actions\n",
    "        # true_actions = np.asarray(traj['actions'][::2])\n",
    "        true_actions = []\n",
    "        pred_actions = []\n",
    "\n",
    "        # observations = np.flip(traj['obs']['agentview_rgb'], 0)  # flip images upright\n",
    "        # observations = np.transpose(traj['obs']['agentview_rgb'], (0, 3, 1, 2))\n",
    "        history_length = 5\n",
    "        history = []\n",
    "        for i, obs in enumerate(traj['obs']['agentview_rgb']):\n",
    "            # obs = cv2.resize(obs, (64, 64))\n",
    "            obs = np.resize(obs, (64, 64, 3))\n",
    "            obs = np.transpose(obs, (2, 0, 1))\n",
    "            if i % 2 == 0:\n",
    "                continue\n",
    "            # manage observation history\n",
    "            if len(history) >= history_length:\n",
    "                history.pop(0)\n",
    "            history.append(obs)\n",
    "\n",
    "            # TODO: get actions predicted by diffusion policy\n",
    "            input = torch.tensor(np.expand_dims(np.stack(history), 0)/255, dtype=torch.float32).to(fabric.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                x_pred = model.sample(input, 10) \n",
    "            pred_actions.append(x_pred.cpu())\n",
    "            true_actions.append(traj['actions'][i])\n",
    "        \n",
    "        pred_actions = np.stack(pred_actions)\n",
    "        true_actions = np.stack(true_actions)\n",
    "        total_mse += np.mean(np.power(true_actions - pred_actions, 2))\n",
    "\n",
    "    total_mse /= len(data.keys())\n",
    "    print(f\"\\tAction MSE: {total_mse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
